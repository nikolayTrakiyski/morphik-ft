############################
#  Morphik Configuration   #
############################

[api]
host = "0.0.0.0"
port = 8000
reload = true

[auth]
jwt_algorithm   = "HS256"
dev_mode        = true
dev_entity_id   = "dev_user"
dev_entity_type = "developer"
dev_permissions = ["read", "write", "admin"]

#######################################################
#   Registered models – keep only what we actually use
#######################################################
[registered_models]
# OpenAI
openai_gpt4o   = { model_name = "gpt-4o" }
openai_gpt4    = { model_name = "gpt-4" }
openai_gpt35   = { model_name = "gpt-3.5-turbo" }

# Anthropic (optional – comment out if you’re not using it)
claude_opus    = { model_name = "claude-3-opus-20240229" }
claude_sonnet  = { model_name = "claude-3-sonnet-20240229" }

# Embedding
openai_embedding        = { model_name = "text-embedding-3-small" }
openai_embedding_large  = { model_name = "text-embedding-3-large" }

#######################################################
#   Component defaults
#######################################################
[completion]
model               = "openai_gpt4o"
default_max_tokens  = 1000
default_temperature = 0.5

[embedding]
model              = "openai_embedding"
dimensions         = 1536          # OpenAI’s text-embedding-3
similarity_metric  = "cosine"

[parser]
chunk_size                 = 6000
chunk_overlap              = 300
use_unstructured_api       = false
use_contextual_chunking    = false
contextual_chunking_model  = "openai_gpt4o"

[parser.vision]
# If you need vision, point to a model that supports it (GPT-4o vision)
model             = "openai_gpt4o"
frame_sample_rate = -1             # disable frame captioning

[reranker]
use_reranker         = true
provider             = "flag"
model_name           = "BAAI/bge-reranker-large"
query_max_length     = 256
passage_max_length   = 512
use_fp16             = true
device               = "cpu"       # inside Docker, safest default

#######################################################
#   Infrastructure
#######################################################
[database]
provider        = "postgres"
# Connection pool
pool_size       = 10
max_overflow    = 15
pool_recycle    = 3600
pool_timeout    = 10
pool_pre_ping   = true
max_retries     = 3
retry_delay     = 1.0
# No host/port here – Morphik uses POSTGRES_URI from the env.

[vector_store]
provider = "pgvector"

[storage]
provider      = "local"
storage_path  = "./storage"

[redis]
host = "redis"   # service name inside the compose network
port = 6379

#######################################################
#   Other features (unchanged, but Ollama refs removed)
#######################################################
[rules]
model       = "openai_gpt4o"
batch_size  = 4096

[morphik]
enable_colpali = true
mode           = "self_hosted"
api_domain     = "api.morphik.ai"

[graph]
model                    = "openai_gpt4o"
enable_entity_resolution = true

[telemetry]
enabled                    = true
honeycomb_enabled          = true
honeycomb_endpoint         = "https://api.honeycomb.io"
honeycomb_proxy_endpoint   = "https://otel-proxy.onrender.com"
service_name               = "databridge-core"
otlp_timeout               = 10
otlp_max_retries           = 3
otlp_retry_delay           = 1
otlp_max_export_batch_size = 512
otlp_schedule_delay_millis = 5000
otlp_max_queue_size        = 2048
